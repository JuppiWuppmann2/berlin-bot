import os
import json
import time
import requests
import re
import unicodedata
import logging
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, WebDriverException
from webdriver_manager.chrome import ChromeDriverManager

from beautify import beautify_text
from bluesky import post_on_bluesky_thread, BlueskyError

# Logging konfigurieren
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

URL = "https://viz.berlin.de/verkehr-in-berlin/baustellen-sperrungen-und-sonstige-storungen/"
STATE_FILE = "data.json"
BACKUP_FILE = "data_backup.json"
MAX_RETRIES = 3
RETRY_DELAY = 10

# ----------------------------- Helper: Normalisierung -----------------------------
def normalize_message(message: str) -> str:
    """Normiert Meldungen f√ºr stabilen Vergleich im State-File."""
    if not message or not isinstance(message, str):
        return ""
    
    msg = message.lower().strip()

    # Unsichtbare Unicode-Zeichen entfernen
    msg = msg.replace("\u200b", "").replace("\xa0", " ")

    # Emojis und Symbole entfernen
    msg = "".join(ch for ch in msg if not unicodedata.category(ch).startswith("So"))

    # Erlaubte Zeichen (Buchstaben, Zahlen, Umlaute, Satzzeichen, Trenner)
    msg = re.sub(r"[^a-z0-9√§√∂√º√ü|,.:;\/\- ]+", " ", msg)

    # Mehrfach-Leerzeichen und Trenner vereinheitlichen
    msg = re.sub(r"\s+", " ", msg).strip()
    msg = msg.replace(" | ", "|")

    return msg

# ----------------------------- Backup-System -----------------------------
def create_backup():
    """Erstellt ein Backup der aktuellen State-Datei."""
    if os.path.exists(STATE_FILE):
        try:
            with open(STATE_FILE, 'r', encoding='utf-8') as src:
                with open(BACKUP_FILE, 'w', encoding='utf-8') as dst:
                    dst.write(src.read())
            logger.info("‚úÖ Backup erstellt")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Backup konnte nicht erstellt werden: {e}")

def restore_from_backup():
    """Stellt State-Datei aus Backup wieder her."""
    if os.path.exists(BACKUP_FILE):
        try:
            with open(BACKUP_FILE, 'r', encoding='utf-8') as src:
                with open(STATE_FILE, 'w', encoding='utf-8') as dst:
                    dst.write(src.read())
            logger.info("‚úÖ State aus Backup wiederhergestellt")
            return True
        except Exception as e:
            logger.error(f"‚ùå Backup-Wiederherstellung fehlgeschlagen: {e}")
    return False

# ----------------------------- Selenium Scraper mit Retry-Logic -----------------------------
def get_viz_updates_with_retry():
    """Scraping mit mehreren Versuchen und Fallback."""
    for attempt in range(MAX_RETRIES):
        try:
            logger.info(f"üîç Scraping-Versuch {attempt + 1}/{MAX_RETRIES}")
            updates = get_viz_updates()
            if updates:  # Erfolg, wenn mindestens eine Meldung gefunden
                logger.info(f"‚úÖ Scraping erfolgreich: {len(updates)} Meldungen")
                return updates
            else:
                logger.warning("‚ö†Ô∏è Keine Meldungen gefunden - k√∂nnte ein Problem sein")
                if attempt < MAX_RETRIES - 1:
                    time.sleep(RETRY_DELAY)
        except Exception as e:
            logger.error(f"‚ùå Scraping-Fehler (Versuch {attempt + 1}): {e}")
            if attempt < MAX_RETRIES - 1:
                time.sleep(RETRY_DELAY)
    
    # Fallback-Scraper versuchen
    logger.info("üîÑ Alle Selenium-Versuche fehlgeschlagen, versuche Fallback-Scraper...")
    try:
        fallback_updates = get_viz_updates_fallback()
        if fallback_updates:
            logger.info(f"‚úÖ Fallback-Scraper erfolgreich: {len(fallback_updates)} Meldungen")
            return fallback_updates
    except Exception as e:
        logger.error(f"‚ùå Auch Fallback-Scraper fehlgeschlagen: {e}")
    
    logger.error("‚ùå Alle Scraping-Versuche (Selenium + Fallback) fehlgeschlagen")
    return []

def get_viz_updates():
    """Scraping-Funktion mit verbesserter Fehlerbehandlung."""
    logger.info("üîç Scraper gestartet...")
    
    options = Options()
    # Stabilere Headless-Einstellungen f√ºr CI-Umgebungen
    options.add_argument("--headless=new")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--disable-gpu")
    options.add_argument("--disable-extensions")
    options.add_argument("--disable-logging")
    options.add_argument("--disable-dev-tools")
    options.add_argument("--window-size=1920,1080")
    options.add_argument("--remote-debugging-port=9222")
    options.add_argument("--user-agent=Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36")
    
    driver = None
    try:
        # Driver-Installation mit Timeout
        service = Service(ChromeDriverManager().install())
        driver = webdriver.Chrome(service=service, options=options)
        driver.set_page_load_timeout(60)
        
        logger.info(f"üì° Lade Seite: {URL}")
        driver.get(URL)
        
        # Warten auf Meldungen mit flexiblerem Selector
        try:
            WebDriverWait(driver, 45).until(
                EC.any_of(
                    EC.presence_of_all_elements_located((By.CSS_SELECTOR, "li.construction-sites-item")),
                    EC.presence_of_all_elements_located((By.CSS_SELECTOR, ".construction-sites-item")),
                    EC.presence_of_all_elements_located((By.CSS_SELECTOR, "li[class*='construction']"))
                )
            )
        except TimeoutException:
            logger.warning("‚ö†Ô∏è Timeout beim Warten auf Meldungen - versuche trotzdem zu scrapen")
        
        # Mehrere Selektoren ausprobieren
        selectors = [
            "li.construction-sites-item",
            ".construction-sites-item", 
            "li[class*='construction']",
            ".item-container li"
        ]
        
        items = []
        for selector in selectors:
            items = driver.find_elements(By.CSS_SELECTOR, selector)
            if items:
                logger.info(f"‚úÖ {len(items)} Meldungen mit Selector '{selector}' gefunden")
                break
        
        if not items:
            logger.warning("‚ö†Ô∏è Keine Meldungen mit bekannten Selektoren gefunden")
            # Fallback: alle li-Elemente
            items = driver.find_elements(By.TAG_NAME, "li")
            logger.info(f"üîÑ Fallback: {len(items)} li-Elemente gefunden")
        
        updates = []
        processed = 0
        
        for li in items:
            try:
                # Flexiblere Textextraktion
                text_content = li.get_attribute('textContent') or li.text
                if not text_content or len(text_content.strip()) < 10:
                    continue
                
                # Strukturierte Extraktion versuchen
                try:
                    title_elem = li.find_element(By.TAG_NAME, "strong")
                    title = title_elem.text.strip()
                except:
                    # Fallback: ersten Teil als Titel verwenden
                    title = text_content.strip().split('\n')[0][:100]
                
                try:
                    span_texts = [span.text.strip() for span in li.find_elements(By.TAG_NAME, "span")]
                    zeitraum = next((t.replace("Zeitraum:", "").strip() for t in span_texts if "Zeitraum" in t), "")
                    location = next((t.replace("Stra√üe:", "").strip() for t in span_texts if "Stra√üe" in t), "")
                    description = " | ".join([t for t in span_texts if "Zeitraum" not in t and "Stra√üe" not in t])
                    
                    parts = [title, description, zeitraum, location]
                    message = " | ".join([p for p in parts if p])
                except:
                    # Fallback: ganzen Text verwenden
                    message = text_content.strip().replace('\n', ' | ')
                
                if message and len(message.strip()) > 5:
                    updates.append(message)
                    processed += 1
                    
            except Exception as e:
                logger.debug(f"Fehler beim Verarbeiten eines Eintrags: {e}")
                continue
        
        logger.info(f"‚úÖ {processed} Meldungen erfolgreich verarbeitet")
        return updates
        
    except WebDriverException as e:
        logger.error(f"‚ùå WebDriver-Fehler: {e}")
        raise
    except Exception as e:
        logger.error(f"‚ùå Unerwarteter Scraping-Fehler: {e}")
        raise
    finally:
        if driver:
            try:
                driver.quit()
                logger.debug("üîÑ WebDriver beendet")
            except:
                pass

# ----------------------------- State Management mit Fehlerbehandlung -----------------------------
def load_state():
    """L√§dt State mit Backup-Fallback."""
    for filepath in [STATE_FILE, BACKUP_FILE]:
        if os.path.exists(filepath):
            try:
                with open(filepath, "r", encoding="utf-8") as f:
                    data = f.read().strip()
                    if not data:  # Datei leer
                        continue
                    state = set(json.loads(data))
                    logger.info(f"‚úÖ State aus {filepath} geladen: {len(state)} Eintr√§ge")
                    return state
            except (json.JSONDecodeError, ValueError) as e:
                logger.warning(f"‚ö†Ô∏è Konnte {filepath} nicht lesen: {e}")
                continue
            except Exception as e:
                logger.error(f"‚ùå Unerwarteter Fehler beim Laden von {filepath}: {e}")
                continue
    
    logger.info("üìù Neuer State wird erstellt")
    return set()

def save_state(state):
    """Speichert State mit Backup."""
    if not isinstance(state, (set, list)):
        logger.error("‚ùå Ung√ºltiger State-Typ")
        return False
    
    try:
        create_backup()
        
        with open(STATE_FILE, "w", encoding="utf-8") as f:
            json.dump(sorted(list(state)), f, ensure_ascii=False, indent=2)
        
        logger.info(f"üíæ State gespeichert: {len(state)} Eintr√§ge")
        return True
    except Exception as e:
        logger.error(f"‚ùå Fehler beim Speichern des States: {e}")
        restore_from_backup()
        return False

# ----------------------------- Verbesserte Post-Logik -----------------------------
def post_updates_safely(items, resolved=False):
    """Postet Updates mit Fehlerbehandlung pro Item."""
    successful_posts = 0
    failed_posts = 0
    
    for norm_item in items:
        try:
            if resolved:
                parts = beautify_text(f"‚úÖ Behoben: {norm_item}", resolved=True)
            else:
                # Original-Text f√ºr neue Meldungen rekonstruieren (vereinfacht)
                parts = beautify_text(norm_item)
            
            logger.info(f"üì§ Poste: {parts[0][:50]}...")
            post_on_bluesky_thread(parts)
            successful_posts += 1
            logger.info("‚úÖ Erfolgreich gepostet!")
            
            # Pause zwischen Posts
            time.sleep(8)
            
        except BlueskyError as e:
            logger.error(f"‚ùå Bluesky-Fehler: {e}")
            failed_posts += 1
            # Bei Rate-Limit l√§nger warten
            if "rate" in str(e).lower() or "limit" in str(e).lower():
                logger.info("‚è≥ Rate-Limit erreicht, warte 60 Sekunden...")
                time.sleep(60)
        except Exception as e:
            logger.error(f"‚ùå Unerwarteter Post-Fehler: {e}")
            failed_posts += 1
    
    logger.info(f"üìä Post-Statistik: {successful_posts} erfolgreich, {failed_posts} fehlgeschlagen")
    return successful_posts, failed_posts

# ----------------------------- Main mit verbesserter Fehlerbehandlung -----------------------------
def main():
    """Hauptfunktion mit umfassender Fehlerbehandlung."""
    logger.info("üöÄ Bot gestartet...")
    
    try:
        # State laden
        prev_state = load_state()
        logger.info(f"üìÇ Bisher gespeicherte Meldungen: {len(prev_state)}")

        # Updates scrapen mit Retry-Logic
        raw_updates = get_viz_updates_with_retry()
        
        if not raw_updates:
            logger.warning("‚ö†Ô∏è Keine Updates erhalten - Bot beendet sich ohne √Ñnderungen")
            return
        
        # Normalisierung mit Fehlerbehandlung
        current_updates = set()
        for update in raw_updates:
            try:
                normalized = normalize_message(update)
                if normalized:  # Nur non-empty hinzuf√ºgen
                    current_updates.add(normalized)
            except Exception as e:
                logger.error(f"‚ùå Fehler bei Normalisierung von '{update[:50]}...': {e}")

        logger.info(f"üîÑ {len(raw_updates)} raw ‚Üí {len(current_updates)} normalisierte Updates")

        # Debug: Beispiel-Normalisierung
        if raw_updates:
            logger.info("üîé Beispiel-Normalisierung:")
            for i, u in enumerate(raw_updates[:2]):
                logger.info(f"  RAW {i+1}: {u[:100]}...")
                logger.info(f"  NORM{i+1}: {normalize_message(u)[:100]}...")

        # Neue und behobene Meldungen identifizieren
        new_items = current_updates - prev_state
        resolved_items = prev_state - current_updates
        
        logger.info(f"üìà Neue Meldungen: {len(new_items)}")
        logger.info(f"üìâ Behobene Meldungen: {len(resolved_items)}")

        # Posts senden
        total_successful = 0
        total_failed = 0
        
        if new_items:
            logger.info("üì§ Poste neue Meldungen...")
            success, failed = post_updates_safely(new_items, resolved=False)
            total_successful += success
            total_failed += failed

        if resolved_items:
            logger.info("üì§ Poste behobene Meldungen...")
            success, failed = post_updates_safely(resolved_items, resolved=True)
            total_successful += success
            total_failed += failed

        # State nur bei erfolgreichem Scraping aktualisieren
        if save_state(current_updates):
            logger.info("üíæ State erfolgreich gespeichert")
        else:
            logger.error("‚ùå State-Speicherung fehlgeschlagen")

        # Zusammenfassung
        logger.info(f"üéØ Bot-Lauf beendet: {total_successful} Posts erfolgreich, {total_failed} fehlgeschlagen")
        
    except KeyboardInterrupt:
        logger.info("‚èπÔ∏è Bot durch Benutzer gestoppt")
    except Exception as e:
        logger.error(f"‚ùå Kritischer Fehler in main(): {e}")
        # Versuche State zu retten
        try:
            restore_from_backup()
            logger.info("üîÑ Backup-State wiederhergestellt")
        except:
            logger.error("‚ùå Auch Backup-Wiederherstellung fehlgeschlagen")
        raise

if __name__ == "__main__":
    main()
